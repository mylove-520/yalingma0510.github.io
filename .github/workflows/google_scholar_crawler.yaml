name: Get Citation Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 8 * * *"

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install Reqs
        run: |
          python -m pip install --upgrade pip
          cd ./google_scholar_crawler
          pip install -r requirements.txt

      - name: Run crawler (bounded)
        run: |
          cd ./google_scholar_crawler
          # 最粗暴的“防卡死”：最多跑 25 分钟就杀掉
          timeout 1500s python3 main.py || true

      - name: Push results
        run: |
          cd ./google_scholar_crawler/results
          git init
          git config --local user.name "${GITHUB_ACTOR}"
          git config --local user.email "${GITHUB_ACTOR}@users.noreply.github.com"
          export remote_repo="https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git"
          git add *.json || true
          git commit -m "Updated Citation Data" || true
          git push "${remote_repo}" HEAD:google-scholar-stats --force
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
